{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TYuhXJ5S5dUl",
    "outputId": "cd547a5a-9db2-4bd7-b61b-41238fd78ecd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.2)\n",
      "Requirement already satisfied: tmdbsimple in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: cinemagoer in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2023.5.1)\n",
      "Requirement already satisfied: requests in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: stop-words in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2018.7.23)\n",
      "Requirement already satisfied: torch in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: SQLAlchemy in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cinemagoer) (2.0.29)\n",
      "Requirement already satisfied: lxml in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cinemagoer) (5.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.21 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from SQLAlchemy->cinemagoer) (3.0.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ankit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install wget tmdbsimple cinemagoer requests stop-words torch matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "-H_U7-Q93yzv"
   },
   "outputs": [],
   "source": [
    "# import torchvision\n",
    "import urllib\n",
    "import requests\n",
    "import json\n",
    "#import imdb\n",
    "import time\n",
    "import itertools\n",
    "import wget\n",
    "import os\n",
    "import tmdbsimple as tmdb\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "import requests\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f=open('Genredict.pckl','rb')\n",
    "Genre_ID_to_name = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "EhQatQdg3y0D"
   },
   "outputs": [],
   "source": [
    "genre_list=sorted(list(Genre_ID_to_name.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "8qlW1MQN3y0N"
   },
   "outputs": [],
   "source": [
    "f6=open('Genredict.pckl','rb')\n",
    "Genre_ID_to_name=pickle.load(f6)\n",
    "f6.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "pKKgOc1S3y0N"
   },
   "outputs": [],
   "source": [
    "genre_list=sorted(list(Genre_ID_to_name.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "2fR96tw83y0P"
   },
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "# model2 = models.Word2Vec.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "model2 = models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "2nWetSfw3y0Q"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# create English stop words list\n",
    "en_stop = get_stop_words('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "FMwiwggxVGgS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANKIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "model_textual = load_model('model_textual.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xMKr3wfL6XgA",
    "outputId": "fc6f96dd-28d5-4c44-b044-7461ea12807f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['ana', 'a', 'college', 'student', 'interviews', 'an', 'enigmatic', 'billionaire', 'entrepreneur', 'christian', 'for', 'her', 'campus', 'periodical', 'a', 'steamy', 'sadomasochistic', 'affair', 'starts', 'between', 'the', 'two', 'whose', 'roots', 'lie', 'in', 'his', 'past']\n",
      "Stopped Tokens: ['ana', 'college', 'student', 'interviews', 'enigmatic', 'billionaire', 'entrepreneur', 'christian', 'campus', 'periodical', 'steamy', 'sadomasochistic', 'affair', 'starts', 'two', 'whose', 'roots', 'lie', 'past']\n",
      "Number of valid tokens: 19\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step\n",
      "Predicted genres: ['Comedy', 'Romance', 'Drama']\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "import numpy as np\n",
    "from gensim import models\n",
    "\n",
    "# Function to preprocess the input text\n",
    "def preprocess_text(input_text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    en_stop = get_stop_words('en')\n",
    "    tokens = tokenizer.tokenize(input_text.lower())\n",
    "    print(\"Tokens:\", tokens)\n",
    "    stopped_tokens = [token for token in tokens if token not in en_stop]\n",
    "    print(\"Stopped Tokens:\", stopped_tokens)\n",
    "    return stopped_tokens\n",
    "\n",
    "# Function to convert the preprocessed text to word vectors\n",
    "def text_to_vectors(preprocessed_text):\n",
    "    word_vectors = []\n",
    "    for token in preprocessed_text:\n",
    "       if token in model2.key_to_index:\n",
    "            word_vectors.append(model2[token])\n",
    "    print(\"Number of valid tokens:\", len(word_vectors))\n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n",
    "# Load the trained textual model\n",
    "model_textual = load_model('model_textual.h5')\n",
    "\n",
    "# Example text input\n",
    "input_text = \"Ana, a college student, interviews an enigmatic billionaire entrepreneur, Christian, for her campus' periodical. A steamy sadomasochistic affair starts between the two, whose roots lie in his past.\"\n",
    "\n",
    "# Preprocess the input text\n",
    "preprocessed_text = preprocess_text(input_text)\n",
    "\n",
    "# Convert the preprocessed text to word vectors\n",
    "input_vectors = text_to_vectors(preprocessed_text)\n",
    "\n",
    "# Reshape input_vectors to match the input shape expected by the model\n",
    "input_vectors = input_vectors.reshape(1, -1)\n",
    "\n",
    "# Make predictions\n",
    "predicted_genres = model_textual.predict(input_vectors)\n",
    "\n",
    "# Get the top 3 predicted genres\n",
    "top_predicted_genres_indices = np.argsort(predicted_genres[0])[-3:]\n",
    "predicted_genres_list = [Genre_ID_to_name[genre_list[index]] for index in top_predicted_genres_indices]\n",
    "\n",
    "print(\"Predicted genres:\", predicted_genres_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
