{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fc594f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "27/27 [==============================] - ETA: 0s - loss: 245.3722 - accuracy: 0.7465 \n",
      "Epoch 1: val_accuracy improved from -inf to 0.84507, saving model to best_model.h5\n",
      "27/27 [==============================] - 494s 18s/step - loss: 245.3722 - accuracy: 0.7465 - val_loss: 0.6167 - val_accuracy: 0.8451\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5584 - accuracy: 0.8856 \n",
      "Epoch 2: val_accuracy improved from 0.84507 to 0.93427, saving model to best_model.h5\n",
      "27/27 [==============================] - 489s 18s/step - loss: 0.5584 - accuracy: 0.8856 - val_loss: 0.3512 - val_accuracy: 0.9343\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.2674 - accuracy: 0.9717 \n",
      "Epoch 3: val_accuracy improved from 0.93427 to 0.94836, saving model to best_model.h5\n",
      "27/27 [==============================] - 488s 18s/step - loss: 0.2674 - accuracy: 0.9717 - val_loss: 0.3018 - val_accuracy: 0.9484\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.1880 - accuracy: 0.9764 \n",
      "Epoch 4: val_accuracy improved from 0.94836 to 0.95305, saving model to best_model.h5\n",
      "27/27 [==============================] - 491s 18s/step - loss: 0.1880 - accuracy: 0.9764 - val_loss: 0.3420 - val_accuracy: 0.9531\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.1501 - accuracy: 0.9858 \n",
      "Epoch 5: val_accuracy improved from 0.95305 to 0.96244, saving model to best_model.h5\n",
      "27/27 [==============================] - 495s 18s/step - loss: 0.1501 - accuracy: 0.9858 - val_loss: 0.3749 - val_accuracy: 0.9624\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0792 - accuracy: 0.9929 \n",
      "Epoch 6: val_accuracy did not improve from 0.96244\n",
      "27/27 [==============================] - 491s 18s/step - loss: 0.0792 - accuracy: 0.9929 - val_loss: 0.3503 - val_accuracy: 0.9484\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0718 - accuracy: 0.9917 \n",
      "Epoch 7: val_accuracy did not improve from 0.96244\n",
      "27/27 [==============================] - 490s 18s/step - loss: 0.0718 - accuracy: 0.9917 - val_loss: 0.7404 - val_accuracy: 0.9343\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0624 - accuracy: 0.9941 \n",
      "Epoch 8: val_accuracy did not improve from 0.96244\n",
      "27/27 [==============================] - 471s 17s/step - loss: 0.0624 - accuracy: 0.9941 - val_loss: 0.3268 - val_accuracy: 0.9577\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0735 - accuracy: 0.9917 \n",
      "Epoch 9: val_accuracy did not improve from 0.96244\n",
      "27/27 [==============================] - 464s 17s/step - loss: 0.0735 - accuracy: 0.9917 - val_loss: 0.2506 - val_accuracy: 0.9484\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0517 - accuracy: 0.9953 \n",
      "Epoch 10: val_accuracy improved from 0.96244 to 0.98122, saving model to best_model.h5\n",
      "27/27 [==============================] - 465s 17s/step - loss: 0.0517 - accuracy: 0.9953 - val_loss: 0.1625 - val_accuracy: 0.9812\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.3069 - accuracy: 0.9737\n",
      "Test Loss: 0.3069150447845459\n",
      "Test Accuracy: 0.9736841917037964\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv3D, MaxPooling3D, Flatten, Dense, Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Constants\n",
    "DATA_DIR = \"C:/Users/madar/OneDrive/Desktop/Dataset\"\n",
    "IMG_SIZE = (64, 64)\n",
    "TEST_SIZE = 0.2\n",
    "VALIDATION_SIZE = 0.2\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_data(data_dir):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    max_frames = 100  # Maximum number of frames per video\n",
    "\n",
    "    for label, category in enumerate([\"newnonviolent\", \"new_violent\"]):\n",
    "        category_dir = os.path.join(data_dir, category)\n",
    "        for filename in os.listdir(category_dir):\n",
    "            video_path = os.path.join(category_dir, filename)\n",
    "            frames, num_frames = extract_frames(video_path)\n",
    "            if frames:\n",
    "                # Pad or trim frames to ensure a fixed length\n",
    "                frames = frames[:max_frames] + [np.zeros_like(frames[0])] * (max_frames - len(frames))\n",
    "                X.append(frames)\n",
    "                y.append(label)\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Function to extract frames from video\n",
    "def extract_frames(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, IMG_SIZE)  # Resize each frame to the specified size\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return frames, num_frames\n",
    "\n",
    "# Load the data\n",
    "X, y = load_data(DATA_DIR)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=42)\n",
    "\n",
    "# Further split train data for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=VALIDATION_SIZE, random_state=42)\n",
    "\n",
    "# Model creation\n",
    "max_frames = 100  # Maximum number of frames per video\n",
    "\n",
    "model = Sequential([\n",
    "    Conv3D(32, kernel_size=(3, 3, 3), activation='relu', input_shape=(max_frames, IMG_SIZE[0], IMG_SIZE[1], 3)),\n",
    "    MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "    Conv3D(64, kernel_size=(3, 3, 3), activation='relu'),\n",
    "    MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Checkpoint to save the best model\n",
    "checkpoint = ModelCheckpoint(\"best_model.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=[checkpoint])\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15bfeacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "# Load the trained model\n",
    "model = load_model(\"best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd222cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 144ms/step\n",
      "Prediction: Non-Violent\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "# Constants\n",
    "IMG_SIZE = (64, 64)\n",
    "max_frames = 100  # Maximum number of frames per video\n",
    "\n",
    "# Function to preprocess input video\n",
    "def preprocess_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, IMG_SIZE)\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # Pad or trim frames to ensure a fixed length\n",
    "    frames = frames[:max_frames] + [np.zeros_like(frames[0])] * (max_frames - len(frames))\n",
    "    \n",
    "    # Convert frames to numpy array and expand dimensions\n",
    "    frames = np.array(frames)\n",
    "    frames = np.expand_dims(frames, axis=0)  # Add batch dimension\n",
    "    return frames\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(\"best_model.h5\")\n",
    "\n",
    "# Function to predict violence/non-violence from input video\n",
    "def predict_violence(video_path):\n",
    "    # Preprocess the input video\n",
    "    input_video = preprocess_video(video_path)\n",
    "    \n",
    "    # Predict violence/non-violence\n",
    "    prediction = model.predict(input_video)\n",
    "    \n",
    "    # Convert prediction to human-readable label\n",
    "    if prediction[0] > 0.5:\n",
    "        return \"Violent\"\n",
    "    else:\n",
    "        return \"Non-Violent\"\n",
    "\n",
    "# Path to the input video\n",
    "input_video_path = \"C:/Users/madar/OneDrive/Desktop/ankit.mp4\"\n",
    "\n",
    "# Predict violence/non-violence\n",
    "prediction = predict_violence(input_video_path)\n",
    "print(\"Prediction:\", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6848da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 13s 1s/step - loss: 0.3069 - accuracy: 0.9737\n",
      "Test Loss: 0.3069150447845459\n",
      "Test Accuracy: 0.9736841917037964\n",
      "9/9 [==============================] - 13s 1s/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       164\n",
      "           1       1.00      0.93      0.96       102\n",
      "\n",
      "    accuracy                           0.97       266\n",
      "   macro avg       0.98      0.97      0.97       266\n",
      "weighted avg       0.97      0.97      0.97       266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Constants\n",
    "DATA_DIR = \"C:/Users/madar/OneDrive/Desktop/Dataset\"\n",
    "IMG_SIZE = (64, 64)\n",
    "TEST_SIZE = 0.2\n",
    "VALIDATION_SIZE = 0.2\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_data(data_dir):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    max_frames = 100  # Maximum number of frames per video\n",
    "\n",
    "    for label, category in enumerate([\"newnonviolent\", \"new_violent\"]):\n",
    "        category_dir = os.path.join(data_dir, category)\n",
    "        for filename in os.listdir(category_dir):\n",
    "            video_path = os.path.join(category_dir, filename)\n",
    "            frames, num_frames = extract_frames(video_path)\n",
    "            if frames:\n",
    "                # Pad or trim frames to ensure a fixed length\n",
    "                frames = frames[:max_frames] + [np.zeros_like(frames[0])] * (max_frames - len(frames))\n",
    "                X.append(frames)\n",
    "                y.append(label)\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Function to extract frames from video\n",
    "def extract_frames(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, IMG_SIZE)  # Resize each frame to the specified size\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return frames, num_frames\n",
    "\n",
    "# Load the data\n",
    "X, y = load_data(DATA_DIR)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=42)\n",
    "\n",
    "# Further split train data for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=VALIDATION_SIZE, random_state=42)\n",
    "\n",
    "# Load the model\n",
    "model = load_model(\"best_model.h5\")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Predictions on test set\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
